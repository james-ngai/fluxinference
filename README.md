# FlexInference

Next-generation inference optimization for agentic LLM workflows.

## Website

Modern landing page showcasing FlexInference technology and research.

## Deployment to GitHub Pages

1. Push this repository to GitHub
2. Go to Settings â†’ Pages
3. Select the branch to deploy (main/master)
4. Save and your site will be live at `https://[username].github.io/FlexInference`

## Local Preview

Open `index.html` in your browser or run:
```bash
python -m http.server 8000
```

## Research

Based on research from CMU 15-779 Advanced Topics in Computer Systems.

For technical details, see: https://github.com/120205690/Agentic-Inference-Server-Optimizations

